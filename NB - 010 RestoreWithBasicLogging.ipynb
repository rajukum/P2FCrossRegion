{"nbformat":4,"nbformat_minor":5,"cells":[{"cell_type":"code","source":["%pip install semantic-link-labs --q"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":7,"statement_ids":[3,4,5,6,7],"state":"finished","livy_statement_state":"available","session_id":"c4adb53f-770b-4622-8062-37428bf8a7e7","normalized_state":"finished","queued_time":"2025-08-23T00:02:32.1873083Z","session_start_time":"2025-08-23T00:02:32.1876581Z","execution_start_time":"2025-08-23T00:02:44.6351182Z","execution_finish_time":"2025-08-23T00:03:07.3806583Z","parent_msg_id":"f762acc2-993f-42fe-8c7c-612c23cdb3c2"},"text/plain":"StatementMeta(, c4adb53f-770b-4622-8062-37428bf8a7e7, 7, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\nNote: you may need to restart the kernel to use updated packages.\nWarning: PySpark kernel has been restarted to use updated packages.\n\n"]}],"execution_count":1,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"303ef1a3-3cb2-47ed-a89a-7ff6baa4262a"},{"cell_type":"code","source":["import sempy_labs as labs\n","import sempy_labs.admin as labs_admin\n","from pyspark.sql import Row\n","import datetime\n","from concurrent.futures import ThreadPoolExecutor, as_completed\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":9,"statement_ids":[9],"state":"finished","livy_statement_state":"available","session_id":"c4adb53f-770b-4622-8062-37428bf8a7e7","normalized_state":"finished","queued_time":"2025-08-23T00:02:32.3365747Z","session_start_time":null,"execution_start_time":"2025-08-23T00:03:12.7533797Z","execution_finish_time":"2025-08-23T00:03:17.4779231Z","parent_msg_id":"5a531efe-b27b-4b1b-b6ab-0dbf0d84ebeb"},"text/plain":"StatementMeta(, c4adb53f-770b-4622-8062-37428bf8a7e7, 9, Finished, Available, Finished)"},"metadata":{}}],"execution_count":2,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"b127ae97-5bb6-4078-86a9-671ba315abab"},{"cell_type":"code","source":["def log_to_table(level, workspaceid, message):\n","    now = datetime.datetime.utcnow().isoformat()\n","    log_df = spark.createDataFrame([Row(timestamp=now, level=level, workspaceId=workspaceid, message=message)])\n","    log_df.write.format(\"delta\").mode(\"append\").saveAsTable(\"Logs_RestoreDatasets\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":10,"statement_ids":[10],"state":"finished","livy_statement_state":"available","session_id":"c4adb53f-770b-4622-8062-37428bf8a7e7","normalized_state":"finished","queued_time":"2025-08-23T00:02:32.5487194Z","session_start_time":null,"execution_start_time":"2025-08-23T00:03:17.4800461Z","execution_finish_time":"2025-08-23T00:03:17.7425017Z","parent_msg_id":"dbdaf7c2-00ed-4162-be2f-0941f9698420"},"text/plain":"StatementMeta(, c4adb53f-770b-4622-8062-37428bf8a7e7, 10, Finished, Available, Finished)"},"metadata":{}}],"execution_count":3,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"d398fcc7-0657-4841-80c3-b736bf41f785"},{"cell_type":"code","source":["def backup_model(ds_name, workspace_id):\n","    try:\n","        labs.restore_semantic_model(\n","            dataset=ds_name,\n","            file_path=f\"{ds_name}.abf\",\n","           allow_overwrite=True,\n","            force_restore=True,\n","            ignore_incompatibilities=True,\n","            workspace=workspace_id\n","        )\n","        msg = f\"Informational: Restore successful for: {ds_name} in workspace {workspace_id}.\"\n","        log_to_table(\"INFO\",workspace_id,msg)\n","        return msg\n","    except Exception as e:\n","       msg = f\"Restore failed for: {ds_name} in workspace {workspace_id} with error: {e}\"\n","       log_to_table(\"ERROR\",workspace_id,msg)\n","       return msg"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":11,"statement_ids":[11],"state":"finished","livy_statement_state":"available","session_id":"c4adb53f-770b-4622-8062-37428bf8a7e7","normalized_state":"finished","queued_time":"2025-08-23T00:02:32.7757352Z","session_start_time":null,"execution_start_time":"2025-08-23T00:03:17.7444861Z","execution_finish_time":"2025-08-23T00:03:18.0066773Z","parent_msg_id":"497aa130-bc5a-446b-9210-6f75e8061723"},"text/plain":"StatementMeta(, c4adb53f-770b-4622-8062-37428bf8a7e7, 11, Finished, Available, Finished)"},"metadata":{}}],"execution_count":4,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"0cc7b297-4f8b-48d7-b916-0f4923b96516"},{"cell_type":"code","source":["workspaces_df = spark.sql(f\"Select DISTINCT Workspace_Id,Dataset_Name from models_discovery_status where Status = 'Success'\")\n","try:\n","      msg = f\" Restore Operation Started.\"\n","      log_to_table(\"INFO\",\"N/A\",msg)\n","\n","      workspace_list = [(row['Dataset_Name'], row['Workspace_Id']) for row in workspaces_df.collect()]\n","      \n","      #print(f\"Datasets to process: {workspace_list}\")\n","      print(f\"Informational:  Restore Started.\")\n","\n","      with ThreadPoolExecutor(max_workers=10) as executor:\n","         futures = [executor.submit(backup_model, ds,ws) for ds,ws in workspace_list]\n","         for future in as_completed(futures):\n","            try: \n","               print(future.result())  # This will raise any exceptions caught during execution\n","            except Exception as e:\n","               print(f\"Exception in future: {e}\")\n","\n","      msg = f\"Restore Operation Completed.\"\n","      log_to_table(\"INFO\",\"N/A\",msg)\n","      print(f\"Informational: Restore Completed.\")\n","except Exception as e:\n","      print(f\"Informational: Restore Failed\")\n","      msg = f\"ðŸ”´Error in Restorep operation: {e}\"\n","      log_to_table(\"ERROR\",\"N/A\",msg)                "],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"63fefb3a-a911-4c58-b0dc-028753c85d72"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","display_name":"synapse_pyspark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"synapse_widget":{"version":"0.1","state":{}},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"lakehouse":{"known_lakehouses":[{"id":"82b79bac-7938-43e2-9292-ca031bde5947"}],"default_lakehouse":"82b79bac-7938-43e2-9292-ca031bde5947","default_lakehouse_name":"metadatascan_global_lh_0822","default_lakehouse_workspace_id":"b1317605-ef25-462c-9dda-82a68b53f242"}}},"notebookName":"NB - 010 RestoreWithBasicLogging(1)"}